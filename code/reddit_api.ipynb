{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e59ceb77",
   "metadata": {},
   "source": [
    "# Ejercicio 2: Reddit API Data Collection & Sentiment Analysis\n",
    "\n",
    "**Autora:** Bianca Peraltilla  \n",
    "**Curso:** Python for Data Science (UP, 2025-II)  \n",
    "\n",
    "---\n",
    "\n",
    "## Objetivo\n",
    "- Conectarme a la API de Reddit usando **PRAW**.  \n",
    "- Extraer publicaciones de subreddits políticos:  \n",
    "  - r/politics  \n",
    "  - r/PoliticalDiscussion  \n",
    "  - r/worldnews  \n",
    "- Guardar la información principal de las publicaciones:  \n",
    "  - título, score (upvotes), número de comentarios, id y url.  \n",
    "- Extraer comentarios de los posts más relevantes (5 por post).  \n",
    "- Almacenar los datos en DataFrames de **pandas** para posterior análisis de sentimiento.  \n",
    "\n",
    "---\n",
    "\n",
    "## Paso 1: Preparación del entorno\n",
    "En este paso:\n",
    "1. Instalo y cargo las librerías necesarias:  \n",
    "   - **praw** → conexión con la API de Reddit.  \n",
    "   - **python-dotenv** → gestión de credenciales de manera segura.  \n",
    "   - **pandas** → manejo y almacenamiento de datos.  \n",
    "2. Verifico que todas las librerías se importan correctamente.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "262db771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet praw python-dotenv pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9485de41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRAW: 7.8.1\n",
      "Pandas: 2.2.2\n",
      "dotenv listo ✔\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "print(\"PRAW:\", praw.__version__)\n",
    "print(\"Pandas:\", pd.__version__)\n",
    "print(\"dotenv listo ✔\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37cfa07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Todo OK, puedes seguir con Reddit.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import praw, pandas as pd\n",
    "    from dotenv import load_dotenv\n",
    "    print(\"✅ Todo OK, puedes seguir con Reddit.\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Falta algo:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b15b5bb",
   "metadata": {},
   "source": [
    "## Paso 2: Configuración de credenciales y conexión con la API de Reddit\n",
    "\n",
    "En este paso:  \n",
    "1. Creo un archivo `.env` que guarda mis credenciales de forma segura.  \n",
    "2. Cargo estas credenciales en el notebook con **python-dotenv**.  \n",
    "3. Establezco la conexión con la API de Reddit usando **PRAW**.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5446b0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conexión exitosa con Reddit\n",
      "Usuario autenticado: Positive-Fly6703\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import praw\n",
    "\n",
    "# Cargar variables desde el archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Conexión a Reddit usando PRAW\n",
    "reddit = praw.Reddit(\n",
    "    client_id=os.getenv(\"REDDIT_CLIENT_ID\"),\n",
    "    client_secret=os.getenv(\"REDDIT_CLIENT_SECRET\"),\n",
    "    user_agent=os.getenv(\"REDDIT_USER_AGENT\"),\n",
    "    username=os.getenv(\"REDDIT_USERNAME\"),\n",
    "    password=os.getenv(\"REDDIT_PASSWORD\")\n",
    ")\n",
    "\n",
    "# Prueba de conexión: verifico mi identidad\n",
    "print(\"✅ Conexión exitosa con Reddit\")\n",
    "print(\"Usuario autenticado:\", reddit.user.me())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830a6842",
   "metadata": {},
   "source": [
    "## Parte 2: Recolección de posts por subreddit\n",
    "\n",
    "**Objetivo:** descargar **20 posts** de cada subreddit político usando **PRAW** y guardar los resultados en un CSV para análisis posterior.\n",
    "\n",
    "- Subreddits objetivo:\n",
    "  - `r/politics`\n",
    "  - `r/PoliticalDiscussion`\n",
    "  - `r/worldnews`\n",
    "- Tipo de listado: dejo **parametrizable** `hot` o `top` (inicio con `hot`).\n",
    "- Campos extraídos por post:\n",
    "  - `title`, `score` (upvotes), `num_comments`, `id`, `url`, `subreddit`\n",
    "- Salida: `output/reddit_posts.csv`\n",
    "\n",
    "> Nota: este dataset será la base para extraer comentarios (siguiente paso) y luego hacer análisis de sentimiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53049038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando 20 posts (hot) de r/politics…\n",
      "  → 20 posts obtenidos\n",
      "Descargando 20 posts (hot) de r/PoliticalDiscussion…\n",
      "  → 20 posts obtenidos\n",
      "Descargando 20 posts (hot) de r/worldnews…\n",
      "  → 20 posts obtenidos\n",
      "\n",
      "✅ Guardé posts en: output\\reddit_posts.csv (total=60)\n",
      "\n",
      "Distribución por subreddit:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_posts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PoliticalDiscussion</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>politics</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldnews</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     n_posts\n",
       "subreddit                   \n",
       "PoliticalDiscussion       20\n",
       "politics                  20\n",
       "worldnews                 20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vista previa:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>politics</td>\n",
       "      <td>1n43su4</td>\n",
       "      <td>Saturday Morning Political Cartoon Thread</td>\n",
       "      <td>34</td>\n",
       "      <td>64</td>\n",
       "      <td>https://www.reddit.com/r/politics/comments/1n4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politics</td>\n",
       "      <td>1n53fzg</td>\n",
       "      <td>Fmr. CDC director says you can no longer trust...</td>\n",
       "      <td>5504</td>\n",
       "      <td>121</td>\n",
       "      <td>https://www.msnbc.com/the-weekend-primetime/wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politics</td>\n",
       "      <td>1n4u384</td>\n",
       "      <td>Trump, 79, Goes on Bizarre AI Posting Spree</td>\n",
       "      <td>14404</td>\n",
       "      <td>1026</td>\n",
       "      <td>https://www.thedailybeast.com/trump-79-goes-on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>politics</td>\n",
       "      <td>1n55zd3</td>\n",
       "      <td>Already Pardoned by Trump, Jan. 6 Rioters Push...</td>\n",
       "      <td>1739</td>\n",
       "      <td>206</td>\n",
       "      <td>https://www.nytimes.com/2025/08/31/us/politics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>politics</td>\n",
       "      <td>1n534ci</td>\n",
       "      <td>Republicans Keep Getting Booed at Their Own To...</td>\n",
       "      <td>2321</td>\n",
       "      <td>71</td>\n",
       "      <td>https://www.motherjones.com/politics/2025/08/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>politics</td>\n",
       "      <td>1n4uee7</td>\n",
       "      <td>Mike Johnson Totally Deflects When Asked About...</td>\n",
       "      <td>7291</td>\n",
       "      <td>176</td>\n",
       "      <td>https://newrepublic.com/post/199857/mike-johns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>politics</td>\n",
       "      <td>1n50hky</td>\n",
       "      <td>Red State Cities Under Consideration for Troop...</td>\n",
       "      <td>2354</td>\n",
       "      <td>206</td>\n",
       "      <td>https://www.newsweek.com/dhs-kristi-noem-red-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>politics</td>\n",
       "      <td>1n4stub</td>\n",
       "      <td>Bernie Sanders endorses popular oyster farmer ...</td>\n",
       "      <td>5594</td>\n",
       "      <td>293</td>\n",
       "      <td>https://www.independent.co.uk/news/world/ameri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>politics</td>\n",
       "      <td>1n51jd4</td>\n",
       "      <td>Donald Trump is on the brink of becoming a dic...</td>\n",
       "      <td>1399</td>\n",
       "      <td>539</td>\n",
       "      <td>https://www.theglobeandmail.com/opinion/articl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>politics</td>\n",
       "      <td>1n569ck</td>\n",
       "      <td>New York's Ultra Rich Are in the Hamptons Frea...</td>\n",
       "      <td>764</td>\n",
       "      <td>127</td>\n",
       "      <td>https://www.rollingstone.com/politics/politics...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit       id                                              title  \\\n",
       "0  politics  1n43su4          Saturday Morning Political Cartoon Thread   \n",
       "1  politics  1n53fzg  Fmr. CDC director says you can no longer trust...   \n",
       "2  politics  1n4u384        Trump, 79, Goes on Bizarre AI Posting Spree   \n",
       "3  politics  1n55zd3  Already Pardoned by Trump, Jan. 6 Rioters Push...   \n",
       "4  politics  1n534ci  Republicans Keep Getting Booed at Their Own To...   \n",
       "5  politics  1n4uee7  Mike Johnson Totally Deflects When Asked About...   \n",
       "6  politics  1n50hky  Red State Cities Under Consideration for Troop...   \n",
       "7  politics  1n4stub  Bernie Sanders endorses popular oyster farmer ...   \n",
       "8  politics  1n51jd4  Donald Trump is on the brink of becoming a dic...   \n",
       "9  politics  1n569ck  New York's Ultra Rich Are in the Hamptons Frea...   \n",
       "\n",
       "   score  num_comments                                                url  \n",
       "0     34            64  https://www.reddit.com/r/politics/comments/1n4...  \n",
       "1   5504           121  https://www.msnbc.com/the-weekend-primetime/wa...  \n",
       "2  14404          1026  https://www.thedailybeast.com/trump-79-goes-on...  \n",
       "3   1739           206  https://www.nytimes.com/2025/08/31/us/politics...  \n",
       "4   2321            71  https://www.motherjones.com/politics/2025/08/r...  \n",
       "5   7291           176  https://newrepublic.com/post/199857/mike-johns...  \n",
       "6   2354           206  https://www.newsweek.com/dhs-kristi-noem-red-s...  \n",
       "7   5594           293  https://www.independent.co.uk/news/world/ameri...  \n",
       "8   1399           539  https://www.theglobeandmail.com/opinion/articl...  \n",
       "9    764           127  https://www.rollingstone.com/politics/politics...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Paso 3 — Descarga de 20 posts por subreddit y guardado en CSV\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Defino parámetros (puedo cambiar \"hot\" por \"top\" si quiero)\n",
    "subreddits = [\"politics\", \"PoliticalDiscussion\", \"worldnews\"]\n",
    "list_type = \"hot\"     # opciones: \"hot\" o \"top\"\n",
    "limit_per_sub = 20    # posts por subreddit\n",
    "\n",
    "# 2) Aseguro carpeta de salida\n",
    "OUTDIR = Path(\"output\")\n",
    "OUTDIR.mkdir(exist_ok=True)\n",
    "\n",
    "def fetch_posts_df(reddit, subreddit: str, list_type: str = \"hot\", limit: int = 20) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Descargo posts de un subreddit y devuelvo un DataFrame limpio\n",
    "    con las columnas que voy a analizar después.\n",
    "    \"\"\"\n",
    "    sr = reddit.subreddit(subreddit)\n",
    "    it = sr.hot(limit=limit) if list_type == \"hot\" else sr.top(limit=limit)\n",
    "\n",
    "    rows = []\n",
    "    for p in it:\n",
    "        rows.append({\n",
    "            \"subreddit\": subreddit,\n",
    "            \"id\": p.id,\n",
    "            \"title\": p.title or \"\",\n",
    "            \"score\": int(getattr(p, \"score\", 0) or 0),\n",
    "            \"num_comments\": int(getattr(p, \"num_comments\", 0) or 0),\n",
    "            \"url\": p.url or \"\"\n",
    "        })\n",
    "    df = pd.DataFrame(rows).drop_duplicates(subset=[\"id\"]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# 3) Recojo 20 por cada subreddit, concateno y guardo\n",
    "frames = []\n",
    "for s in subreddits:\n",
    "    print(f\"Descargando {limit_per_sub} posts ({list_type}) de r/{s}…\")\n",
    "    df_s = fetch_posts_df(reddit, s, list_type=list_type, limit=limit_per_sub)\n",
    "    print(f\"  → {len(df_s)} posts obtenidos\")\n",
    "    frames.append(df_s)\n",
    "    time.sleep(0.8)  # pequeña pausa para ser amable con la API\n",
    "\n",
    "posts = pd.concat(frames, ignore_index=True)\n",
    "posts_path = OUTDIR / \"reddit_posts.csv\"\n",
    "posts.to_csv(posts_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"\\n✅ Guardé posts en: {posts_path} (total={len(posts)})\")\n",
    "print(\"\\nDistribución por subreddit:\")\n",
    "display(posts.groupby(\"subreddit\")[\"id\"].count().to_frame(\"n_posts\"))\n",
    "\n",
    "print(\"\\nVista previa:\")\n",
    "display(posts.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbf6704",
   "metadata": {},
   "source": [
    "## Parte 3: Recolección de comentarios (hasta 5 por post)\n",
    "\n",
    "**Objetivo:** para cada post descargado anteriormente, recolecto **hasta 5 comentarios** con más puntaje y los guardo en un CSV.\n",
    "\n",
    "- Fuente: el archivo `output/reddit_posts.csv` generado en el paso anterior.\n",
    "- Para cada `post_id`:\n",
    "  - Expando comentarios y filtro los que están vacíos o borrados.\n",
    "  - Tomo los **5 con mayor `score`** (si hay menos, guardo los que existan).\n",
    "- Campos por comentario:\n",
    "  - `post_id` (para enlazar con la tabla de posts)\n",
    "  - `body` (texto del comentario, sin saltos de línea)\n",
    "  - `score` (upvotes del comentario)\n",
    "- Salida: `output/reddit_comments.csv`\n",
    "\n",
    "> Nota: uso pausas cortas para no golpear la API y manejo errores por post, así no se detiene todo el proceso si uno falla.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d9a316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de posts cargados: 60\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>politics</td>\n",
       "      <td>1n43su4</td>\n",
       "      <td>Saturday Morning Political Cartoon Thread</td>\n",
       "      <td>34</td>\n",
       "      <td>64</td>\n",
       "      <td>https://www.reddit.com/r/politics/comments/1n4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politics</td>\n",
       "      <td>1n53fzg</td>\n",
       "      <td>Fmr. CDC director says you can no longer trust...</td>\n",
       "      <td>5504</td>\n",
       "      <td>121</td>\n",
       "      <td>https://www.msnbc.com/the-weekend-primetime/wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politics</td>\n",
       "      <td>1n4u384</td>\n",
       "      <td>Trump, 79, Goes on Bizarre AI Posting Spree</td>\n",
       "      <td>14404</td>\n",
       "      <td>1026</td>\n",
       "      <td>https://www.thedailybeast.com/trump-79-goes-on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>politics</td>\n",
       "      <td>1n55zd3</td>\n",
       "      <td>Already Pardoned by Trump, Jan. 6 Rioters Push...</td>\n",
       "      <td>1739</td>\n",
       "      <td>206</td>\n",
       "      <td>https://www.nytimes.com/2025/08/31/us/politics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>politics</td>\n",
       "      <td>1n534ci</td>\n",
       "      <td>Republicans Keep Getting Booed at Their Own To...</td>\n",
       "      <td>2321</td>\n",
       "      <td>71</td>\n",
       "      <td>https://www.motherjones.com/politics/2025/08/r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit       id                                              title  \\\n",
       "0  politics  1n43su4          Saturday Morning Political Cartoon Thread   \n",
       "1  politics  1n53fzg  Fmr. CDC director says you can no longer trust...   \n",
       "2  politics  1n4u384        Trump, 79, Goes on Bizarre AI Posting Spree   \n",
       "3  politics  1n55zd3  Already Pardoned by Trump, Jan. 6 Rioters Push...   \n",
       "4  politics  1n534ci  Republicans Keep Getting Booed at Their Own To...   \n",
       "\n",
       "   score  num_comments                                                url  \n",
       "0     34            64  https://www.reddit.com/r/politics/comments/1n4...  \n",
       "1   5504           121  https://www.msnbc.com/the-weekend-primetime/wa...  \n",
       "2  14404          1026  https://www.thedailybeast.com/trump-79-goes-on...  \n",
       "3   1739           206  https://www.nytimes.com/2025/08/31/us/politics...  \n",
       "4   2321            71  https://www.motherjones.com/politics/2025/08/r...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Guardé comentarios en: output\\reddit_comments.csv (total=300)\n",
      "ℹ️ Posts con error: 0\n",
      "\n",
      "Ejemplos (5 filas):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1n43su4</td>\n",
       "      <td>Jen Sorensen:   [Web’s end]( https://www.daily...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1n43su4</td>\n",
       "      <td>Pedro X. Molina:   [The symbol…](https://www.g...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1n43su4</td>\n",
       "      <td>Brian McFadden - [Anti-Heroes](https://www.dai...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1n43su4</td>\n",
       "      <td>Ben Jennings   [Back to school sale](https://w...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1n43su4</td>\n",
       "      <td>Ratt- [Who is to blame?](https://www.dailycart...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                               body  score\n",
       "0  1n43su4  Jen Sorensen:   [Web’s end]( https://www.daily...     29\n",
       "1  1n43su4  Pedro X. Molina:   [The symbol…](https://www.g...     24\n",
       "2  1n43su4  Brian McFadden - [Anti-Heroes](https://www.dai...     20\n",
       "3  1n43su4  Ben Jennings   [Back to school sale](https://w...     19\n",
       "4  1n43su4  Ratt- [Who is to blame?](https://www.dailycart...     17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cantidad de comentarios por post (top 10):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_comments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1bwbuka</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1msce9l</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1mxwbnt</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1myv6j9</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1mz6m1w</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1mzn0u5</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1mzt9qg</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1mzv1a2</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1n09ltj</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1n0wgiu</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         n_comments\n",
       "post_id            \n",
       "1bwbuka           5\n",
       "1msce9l           5\n",
       "1mxwbnt           5\n",
       "1myv6j9           5\n",
       "1mz6m1w           5\n",
       "1mzn0u5           5\n",
       "1mzt9qg           5\n",
       "1mzv1a2           5\n",
       "1n09ltj           5\n",
       "1n0wgiu           5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Paso 4 — Descarga de comentarios (hasta 5 por post) y guardado a CSV\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Cargo los posts del paso anterior\n",
    "OUTDIR = Path(\"output\")\n",
    "posts_path = OUTDIR / \"reddit_posts.csv\"\n",
    "assert posts_path.exists(), \"No encuentro output/reddit_posts.csv. Corre primero el Paso 3.\"\n",
    "\n",
    "posts = pd.read_csv(posts_path)\n",
    "\n",
    "print(f\"Total de posts cargados: {len(posts)}\")\n",
    "display(posts.head())\n",
    "\n",
    "# 2) Función para traer comentarios top por post_id\n",
    "def fetch_top_comments(reddit, post_id: str, per_post: int = 5):\n",
    "    \"\"\"\n",
    "    Devuelve lista de diccionarios con: post_id, body, score.\n",
    "    Tomo hasta 'per_post' comentarios mejor puntuados.\n",
    "    \"\"\"\n",
    "    subm = reddit.submission(id=post_id)\n",
    "    subm.comments.replace_more(limit=0)  # expando \"MoreComments\"\n",
    "    comments = subm.comments.list()\n",
    "\n",
    "    # Filtro borrados/vacíos y ordeno por score desc\n",
    "    clean = []\n",
    "    for c in comments:\n",
    "        body = getattr(c, \"body\", None)\n",
    "        if body and body not in (\"[deleted]\", \"[removed]\"):\n",
    "            clean.append(c)\n",
    "    clean.sort(key=lambda c: getattr(c, \"score\", 0) or 0, reverse=True)\n",
    "\n",
    "    rows = []\n",
    "    for c in clean[:per_post]:\n",
    "        txt = (c.body or \"\").replace(\"\\n\", \" \").strip()\n",
    "        rows.append({\"post_id\": post_id, \"body\": txt, \"score\": int(getattr(c, \"score\", 0) or 0)})\n",
    "    return rows\n",
    "\n",
    "# 3) Itero por todos los posts y voy acumulando\n",
    "all_comments = []\n",
    "errors = 0\n",
    "\n",
    "for i, pid in enumerate(posts[\"id\"].tolist(), start=1):\n",
    "    try:\n",
    "        rows = fetch_top_comments(reddit, pid, per_post=5)\n",
    "        all_comments.extend(rows)\n",
    "        # Pausa breve para ser amable con la API\n",
    "        time.sleep(0.5)\n",
    "    except Exception as e:\n",
    "        errors += 1\n",
    "        print(f\"⚠️ Error en post {pid}: {e}\")\n",
    "        time.sleep(1.0)\n",
    "\n",
    "# 4) Armo DataFrame y guardo\n",
    "comments = pd.DataFrame(all_comments, columns=[\"post_id\", \"body\", \"score\"])\n",
    "comments_path = OUTDIR / \"reddit_comments.csv\"\n",
    "comments.to_csv(comments_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"\\n✅ Guardé comentarios en: {comments_path} (total={len(comments)})\")\n",
    "print(f\"ℹ️ Posts con error: {errors}\")\n",
    "\n",
    "# 5) Chequeos rápidos de integridad\n",
    "print(\"\\nEjemplos (5 filas):\")\n",
    "display(comments.head())\n",
    "\n",
    "print(\"\\nCantidad de comentarios por post (top 10):\")\n",
    "display(comments.groupby(\"post_id\")[\"score\"].count().sort_values(ascending=False).head(10).to_frame(\"n_comments\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb88dd72",
   "metadata": {},
   "source": [
    "### Resultado de la recolección de comentarios\n",
    "- Archivo generado: `output/reddit_comments.csv`\n",
    "- Claves:\n",
    "  - `post_id` me permite enlazar con `reddit_posts.csv`.\n",
    "  - `score` ayuda a priorizar comentarios más relevantes.\n",
    "  - `body` es el texto que luego usaré para análisis de sentimiento.\n",
    "- Con esto cierro la recolección de datos (posts + comentarios) y quedo lista para la fase de **análisis exploratorio / sentiment analysis**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68094816",
   "metadata": {},
   "source": [
    "## Parte final: Verificación del enlace post–comentario + Mini-EDA\n",
    "\n",
    "**Objetivo:**  \n",
    "- Verifico que cada comentario (`reddit_comments.csv`) está correctamente vinculado a su post padre (`reddit_posts.csv`) mediante `post_id`.  \n",
    "- Hago un análisis rápido (EDA) para agregar valor:\n",
    "  - Top posts por `score` (upvotes).\n",
    "  - Posts con más comentarios (según `num_comments`).\n",
    "  - Comentarios por subreddit.\n",
    "  - Top posts por “impacto de comentarios” (suma de `score` de los comentarios).\n",
    "\n",
    "Además, genero un archivo `output/reddit_merged_sample.csv` con ejemplo de unión *post + comentario* para evidenciar el enlace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40343210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts: 60 filas | Comments: 300 filas\n",
      "Comentarios sin post emparejado: 0\n",
      "✅ Evidencia guardada: output\\reddit_merged_sample.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>comment_body</th>\n",
       "      <th>comment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1n43su4</td>\n",
       "      <td>politics</td>\n",
       "      <td>Saturday Morning Political Cartoon Thread</td>\n",
       "      <td>Jen Sorensen:   [Web’s end]( https://www.daily...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1n43su4</td>\n",
       "      <td>politics</td>\n",
       "      <td>Saturday Morning Political Cartoon Thread</td>\n",
       "      <td>Pedro X. Molina:   [The symbol…](https://www.g...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1n43su4</td>\n",
       "      <td>politics</td>\n",
       "      <td>Saturday Morning Political Cartoon Thread</td>\n",
       "      <td>Brian McFadden - [Anti-Heroes](https://www.dai...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1n43su4</td>\n",
       "      <td>politics</td>\n",
       "      <td>Saturday Morning Political Cartoon Thread</td>\n",
       "      <td>Ben Jennings   [Back to school sale](https://w...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1n43su4</td>\n",
       "      <td>politics</td>\n",
       "      <td>Saturday Morning Political Cartoon Thread</td>\n",
       "      <td>Ratt- [Who is to blame?](https://www.dailycart...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1n53fzg</td>\n",
       "      <td>politics</td>\n",
       "      <td>Fmr. CDC director says you can no longer trust...</td>\n",
       "      <td>As a reminder, this subreddit [is for civil di...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1n53fzg</td>\n",
       "      <td>politics</td>\n",
       "      <td>Fmr. CDC director says you can no longer trust...</td>\n",
       "      <td>Everything's become an opinion piece from cons...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1n53fzg</td>\n",
       "      <td>politics</td>\n",
       "      <td>Fmr. CDC director says you can no longer trust...</td>\n",
       "      <td>Just in case any Americans are looking for rel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1n53fzg</td>\n",
       "      <td>politics</td>\n",
       "      <td>Fmr. CDC director says you can no longer trust...</td>\n",
       "      <td>I don’t trust any agency under Trump’s control...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1n53fzg</td>\n",
       "      <td>politics</td>\n",
       "      <td>Fmr. CDC director says you can no longer trust...</td>\n",
       "      <td>Step 1 : Train your populace to not trust inst...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id subreddit                                              title  \\\n",
       "0  1n43su4  politics          Saturday Morning Political Cartoon Thread   \n",
       "1  1n43su4  politics          Saturday Morning Political Cartoon Thread   \n",
       "2  1n43su4  politics          Saturday Morning Political Cartoon Thread   \n",
       "3  1n43su4  politics          Saturday Morning Political Cartoon Thread   \n",
       "4  1n43su4  politics          Saturday Morning Political Cartoon Thread   \n",
       "5  1n53fzg  politics  Fmr. CDC director says you can no longer trust...   \n",
       "6  1n53fzg  politics  Fmr. CDC director says you can no longer trust...   \n",
       "7  1n53fzg  politics  Fmr. CDC director says you can no longer trust...   \n",
       "8  1n53fzg  politics  Fmr. CDC director says you can no longer trust...   \n",
       "9  1n53fzg  politics  Fmr. CDC director says you can no longer trust...   \n",
       "\n",
       "                                        comment_body  comment_score  \n",
       "0  Jen Sorensen:   [Web’s end]( https://www.daily...             29  \n",
       "1  Pedro X. Molina:   [The symbol…](https://www.g...             24  \n",
       "2  Brian McFadden - [Anti-Heroes](https://www.dai...             20  \n",
       "3  Ben Jennings   [Back to school sale](https://w...             19  \n",
       "4  Ratt- [Who is to blame?](https://www.dailycart...             17  \n",
       "5  As a reminder, this subreddit [is for civil di...              1  \n",
       "6  Everything's become an opinion piece from cons...              1  \n",
       "7  Just in case any Americans are looking for rel...              1  \n",
       "8  I don’t trust any agency under Trump’s control...              1  \n",
       "9  Step 1 : Train your populace to not trust inst...              1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 posts por score (upvotes):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>Company behind Jack Daniel's says Canadian boy...</td>\n",
       "      <td>18658</td>\n",
       "      <td>881</td>\n",
       "      <td>https://www.cbc.ca/news/canada/nova-scotia/bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politics</td>\n",
       "      <td>Trump, 79, Goes on Bizarre AI Posting Spree</td>\n",
       "      <td>14404</td>\n",
       "      <td>1026</td>\n",
       "      <td>https://www.thedailybeast.com/trump-79-goes-on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>Russia’s 2025 Summer Offensive Ends in Heavy L...</td>\n",
       "      <td>12682</td>\n",
       "      <td>456</td>\n",
       "      <td>https://united24media.com/latest-news/russias-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>US spies stoked separatism in Greenland, Denma...</td>\n",
       "      <td>10464</td>\n",
       "      <td>492</td>\n",
       "      <td>https://euobserver.com/eu-and-the-world/ar4837...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>politics</td>\n",
       "      <td>Trump's distractions fail as Congress is set t...</td>\n",
       "      <td>9093</td>\n",
       "      <td>106</td>\n",
       "      <td>https://www.msnbc.com/the-briefing-with-jen-ps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>politics</td>\n",
       "      <td>Mike Johnson Totally Deflects When Asked About...</td>\n",
       "      <td>7291</td>\n",
       "      <td>176</td>\n",
       "      <td>https://newrepublic.com/post/199857/mike-johns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>Venezuela warns US to stay away from national ...</td>\n",
       "      <td>6055</td>\n",
       "      <td>423</td>\n",
       "      <td>https://www.trtworld.com/world/article/2cd488f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>politics</td>\n",
       "      <td>Bernie Sanders endorses popular oyster farmer ...</td>\n",
       "      <td>5594</td>\n",
       "      <td>293</td>\n",
       "      <td>https://www.independent.co.uk/news/world/ameri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politics</td>\n",
       "      <td>Fmr. CDC director says you can no longer trust...</td>\n",
       "      <td>5504</td>\n",
       "      <td>121</td>\n",
       "      <td>https://www.msnbc.com/the-weekend-primetime/wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>Argentina: Milei government panics after fresh...</td>\n",
       "      <td>4933</td>\n",
       "      <td>204</td>\n",
       "      <td>https://batimes.com.ar/news/argentina/milei-go...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subreddit                                              title  score  \\\n",
       "59  worldnews  Company behind Jack Daniel's says Canadian boy...  18658   \n",
       "2    politics        Trump, 79, Goes on Bizarre AI Posting Spree  14404   \n",
       "44  worldnews  Russia’s 2025 Summer Offensive Ends in Heavy L...  12682   \n",
       "41  worldnews  US spies stoked separatism in Greenland, Denma...  10464   \n",
       "18   politics  Trump's distractions fail as Congress is set t...   9093   \n",
       "5    politics  Mike Johnson Totally Deflects When Asked About...   7291   \n",
       "43  worldnews  Venezuela warns US to stay away from national ...   6055   \n",
       "7    politics  Bernie Sanders endorses popular oyster farmer ...   5594   \n",
       "1    politics  Fmr. CDC director says you can no longer trust...   5504   \n",
       "52  worldnews  Argentina: Milei government panics after fresh...   4933   \n",
       "\n",
       "    num_comments                                                url  \n",
       "59           881  https://www.cbc.ca/news/canada/nova-scotia/bro...  \n",
       "2           1026  https://www.thedailybeast.com/trump-79-goes-on...  \n",
       "44           456  https://united24media.com/latest-news/russias-...  \n",
       "41           492  https://euobserver.com/eu-and-the-world/ar4837...  \n",
       "18           106  https://www.msnbc.com/the-briefing-with-jen-ps...  \n",
       "5            176  https://newrepublic.com/post/199857/mike-johns...  \n",
       "43           423  https://www.trtworld.com/world/article/2cd488f...  \n",
       "7            293  https://www.independent.co.uk/news/world/ameri...  \n",
       "1            121  https://www.msnbc.com/the-weekend-primetime/wa...  \n",
       "52           204  https://batimes.com.ar/news/argentina/milei-go...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 posts por número de comentarios (según metadata del post):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PoliticalDiscussion</td>\n",
       "      <td>Casual Questions Thread</td>\n",
       "      <td>8308</td>\n",
       "      <td>88</td>\n",
       "      <td>https://www.reddit.com/r/PoliticalDiscussion/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politics</td>\n",
       "      <td>Trump, 79, Goes on Bizarre AI Posting Spree</td>\n",
       "      <td>1026</td>\n",
       "      <td>14404</td>\n",
       "      <td>https://www.thedailybeast.com/trump-79-goes-on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>Aid flotilla with Greta Thunberg set to sail f...</td>\n",
       "      <td>1025</td>\n",
       "      <td>3180</td>\n",
       "      <td>https://www.theguardian.com/environment/2025/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>Company behind Jack Daniel's says Canadian boy...</td>\n",
       "      <td>881</td>\n",
       "      <td>18658</td>\n",
       "      <td>https://www.cbc.ca/news/canada/nova-scotia/bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>politics</td>\n",
       "      <td>Donald Trump is on the brink of becoming a dic...</td>\n",
       "      <td>539</td>\n",
       "      <td>1399</td>\n",
       "      <td>https://www.theglobeandmail.com/opinion/articl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>US spies stoked separatism in Greenland, Denma...</td>\n",
       "      <td>492</td>\n",
       "      <td>10464</td>\n",
       "      <td>https://euobserver.com/eu-and-the-world/ar4837...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PoliticalDiscussion</td>\n",
       "      <td>What do you think about Gavin Newsom's new soc...</td>\n",
       "      <td>489</td>\n",
       "      <td>745</td>\n",
       "      <td>https://www.reddit.com/r/PoliticalDiscussion/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>Russia’s 2025 Summer Offensive Ends in Heavy L...</td>\n",
       "      <td>456</td>\n",
       "      <td>12682</td>\n",
       "      <td>https://united24media.com/latest-news/russias-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>Venezuela warns US to stay away from national ...</td>\n",
       "      <td>423</td>\n",
       "      <td>6055</td>\n",
       "      <td>https://www.trtworld.com/world/article/2cd488f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>politics</td>\n",
       "      <td>Blocking tariffs would be \"end of the United S...</td>\n",
       "      <td>351</td>\n",
       "      <td>626</td>\n",
       "      <td>https://www.axios.com/2025/08/31/trump-tariffs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              subreddit                                              title  \\\n",
       "20  PoliticalDiscussion                            Casual Questions Thread   \n",
       "2              politics        Trump, 79, Goes on Bizarre AI Posting Spree   \n",
       "54            worldnews  Aid flotilla with Greta Thunberg set to sail f...   \n",
       "59            worldnews  Company behind Jack Daniel's says Canadian boy...   \n",
       "8              politics  Donald Trump is on the brink of becoming a dic...   \n",
       "41            worldnews  US spies stoked separatism in Greenland, Denma...   \n",
       "23  PoliticalDiscussion  What do you think about Gavin Newsom's new soc...   \n",
       "44            worldnews  Russia’s 2025 Summer Offensive Ends in Heavy L...   \n",
       "43            worldnews  Venezuela warns US to stay away from national ...   \n",
       "19             politics  Blocking tariffs would be \"end of the United S...   \n",
       "\n",
       "    num_comments  score                                                url  \n",
       "20          8308     88  https://www.reddit.com/r/PoliticalDiscussion/c...  \n",
       "2           1026  14404  https://www.thedailybeast.com/trump-79-goes-on...  \n",
       "54          1025   3180  https://www.theguardian.com/environment/2025/a...  \n",
       "59           881  18658  https://www.cbc.ca/news/canada/nova-scotia/bro...  \n",
       "8            539   1399  https://www.theglobeandmail.com/opinion/articl...  \n",
       "41           492  10464  https://euobserver.com/eu-and-the-world/ar4837...  \n",
       "23           489    745  https://www.reddit.com/r/PoliticalDiscussion/c...  \n",
       "44           456  12682  https://united24media.com/latest-news/russias-...  \n",
       "43           423   6055  https://www.trtworld.com/world/article/2cd488f...  \n",
       "19           351    626  https://www.axios.com/2025/08/31/trump-tariffs...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comentarios por subreddit (conteo) según el dataset de comentarios:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_comments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PoliticalDiscussion</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>politics</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldnews</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     n_comments\n",
       "subreddit                      \n",
       "PoliticalDiscussion         100\n",
       "politics                    100\n",
       "worldnews                   100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 posts por 'impacto de comentarios' (suma de score de comentarios):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>comment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1n4u384</td>\n",
       "      <td>Trump, 79, Goes on Bizarre AI Posting Spree</td>\n",
       "      <td>politics</td>\n",
       "      <td>23283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1n4amb2</td>\n",
       "      <td>Company behind Jack Daniel's says Canadian boy...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>12388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1n4lyl2</td>\n",
       "      <td>Aid flotilla with Greta Thunberg set to sail f...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>8441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1n55kzl</td>\n",
       "      <td>US spies stoked separatism in Greenland, Denma...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>7468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1n4ty5j</td>\n",
       "      <td>Venezuela warns US to stay away from national ...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>5637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1n54p1m</td>\n",
       "      <td>Trump Officials Discussed $500M Alberta (Canad...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>5553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1n4jkim</td>\n",
       "      <td>Argentina: Milei government panics after fresh...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>4221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1n4qqg1</td>\n",
       "      <td>Russia’s 2025 Summer Offensive Ends in Heavy L...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>4096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1n4stub</td>\n",
       "      <td>Bernie Sanders endorses popular oyster farmer ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>3298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1n4uee7</td>\n",
       "      <td>Mike Johnson Totally Deflects When Asked About...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    post_id                                              title  subreddit  \\\n",
       "34  1n4u384        Trump, 79, Goes on Bizarre AI Posting Spree   politics   \n",
       "21  1n4amb2  Company behind Jack Daniel's says Canadian boy...  worldnews   \n",
       "25  1n4lyl2  Aid flotilla with Greta Thunberg set to sail f...  worldnews   \n",
       "55  1n55kzl  US spies stoked separatism in Greenland, Denma...  worldnews   \n",
       "33  1n4ty5j  Venezuela warns US to stay away from national ...  worldnews   \n",
       "52  1n54p1m  Trump Officials Discussed $500M Alberta (Canad...  worldnews   \n",
       "22  1n4jkim  Argentina: Milei government panics after fresh...  worldnews   \n",
       "27  1n4qqg1  Russia’s 2025 Summer Offensive Ends in Heavy L...  worldnews   \n",
       "31  1n4stub  Bernie Sanders endorses popular oyster farmer ...   politics   \n",
       "35  1n4uee7  Mike Johnson Totally Deflects When Asked About...   politics   \n",
       "\n",
       "    comment_score  \n",
       "34          23283  \n",
       "21          12388  \n",
       "25           8441  \n",
       "55           7468  \n",
       "33           5637  \n",
       "52           5553  \n",
       "22           4221  \n",
       "27           4096  \n",
       "31           3298  \n",
       "35           2890  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Verifico el enlace post–comentario y hago un pequeño EDA\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "OUTDIR = Path(\"output\")\n",
    "posts_path = OUTDIR / \"reddit_posts.csv\"\n",
    "comments_path = OUTDIR / \"reddit_comments.csv\"\n",
    "\n",
    "# 1) Cargo las tablas generadas\n",
    "df_posts = pd.read_csv(posts_path)\n",
    "df_comments = pd.read_csv(comments_path)\n",
    "\n",
    "print(f\"Posts: {len(df_posts)} filas | Comments: {len(df_comments)} filas\")\n",
    "\n",
    "# 2) Verificación: uno comentarios con su post por el id\n",
    "merged = df_comments.merge(\n",
    "    df_posts[[\"id\", \"title\", \"subreddit\", \"score\", \"num_comments\", \"url\"]],\n",
    "    left_on=\"post_id\",\n",
    "    right_on=\"id\",\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\"  # cada comment pertenece a un único post\n",
    ")\n",
    "\n",
    "# Reviso integridad del link (cuántos comentarios quedaron sin post)\n",
    "missing = merged[\"title\"].isna().sum()\n",
    "print(f\"Comentarios sin post emparejado: {missing}\")\n",
    "\n",
    "# 3) Exporto una muestra como evidencia del link post–comentario\n",
    "sample_cols = [\"post_id\", \"subreddit\", \"title\", \"comment_body\", \"comment_score\"]\n",
    "# Si tus columnas se llaman \"body\" y \"score\" en comments, ajusto:\n",
    "if \"comment_body\" not in merged.columns:\n",
    "    merged = merged.rename(columns={\"body\": \"comment_body\"})\n",
    "if \"comment_score\" not in merged.columns:\n",
    "    merged = merged.rename(columns={\"score_x\": \"comment_score\"})  # por si hay colisión de nombre\n",
    "    if \"comment_score\" not in merged.columns and \"score\" in merged.columns:\n",
    "        merged = merged.rename(columns={\"score\": \"comment_score\"})\n",
    "\n",
    "evidence = merged[sample_cols].head(50)\n",
    "evidence_path = OUTDIR / \"reddit_merged_sample.csv\"\n",
    "evidence.to_csv(evidence_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"✅ Evidencia guardada: {evidence_path}\")\n",
    "\n",
    "display(evidence.head(10))\n",
    "\n",
    "# 4) Mini-EDA que agrega valor\n",
    "print(\"\\nTop 10 posts por score (upvotes):\")\n",
    "top_by_score = df_posts.sort_values(\"score\", ascending=False).head(10)[[\"subreddit\", \"title\", \"score\", \"num_comments\", \"url\"]]\n",
    "display(top_by_score)\n",
    "\n",
    "print(\"\\nTop 10 posts por número de comentarios (según metadata del post):\")\n",
    "top_by_num_comments = df_posts.sort_values(\"num_comments\", ascending=False).head(10)[[\"subreddit\", \"title\", \"num_comments\", \"score\", \"url\"]]\n",
    "display(top_by_num_comments)\n",
    "\n",
    "print(\"\\nComentarios por subreddit (conteo) según el dataset de comentarios:\")\n",
    "comments_per_sub = merged.groupby(\"subreddit\")[\"comment_body\"].count().sort_values(ascending=False).to_frame(\"n_comments\")\n",
    "display(comments_per_sub)\n",
    "\n",
    "print(\"\\nTop 10 posts por 'impacto de comentarios' (suma de score de comentarios):\")\n",
    "impact = merged.groupby([\"post_id\", \"title\", \"subreddit\"], dropna=False)[\"comment_score\"].sum().reset_index()\n",
    "impact = impact.sort_values(\"comment_score\", ascending=False).head(10)\n",
    "display(impact)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec30b33",
   "metadata": {},
   "source": [
    "# Conclusiones — Ejercicio 2: Reddit API & Sentiment Data Collection\n",
    "\n",
    "- Se logró **conectar exitosamente a la API de Reddit (PRAW)** usando credenciales seguras guardadas en `.env`.\n",
    "- Se recolectaron **20 posts por cada subreddit** (`r/politics`, `r/PoliticalDiscussion`, `r/worldnews`), guardando título, score, n_comments, id y url.\n",
    "- Se descargaron hasta **5 comentarios principales por post**, enlazándolos a su publicación mediante `post_id`.\n",
    "- Los datos quedaron almacenados en dos CSV (`reddit_posts.csv` y `reddit_comments.csv`) y además se verificó la relación posts–comentarios con un `merge`.\n",
    "\n",
    "### Insights del mini-EDA:\n",
    "- Los posts con mayor puntaje (upvotes) y con más comentarios no siempre coinciden, lo que refleja diferencias entre “popularidad” y “participación”.\n",
    "- `r/politics` y `r/worldnews` concentran la mayoría de los comentarios en el dataset, confirmando su mayor nivel de interacción frente a `r/PoliticalDiscussion`.\n",
    "- Algunos posts destacan por su **alto “impacto de comentarios”** (suma de score de los comentarios), lo que permite detectar hilos donde la discusión generó mayor resonancia.\n",
    "- Estos datos recolectados pueden servir como base para un análisis de **sentimiento** en los comentarios (positivo/negativo), enriqueciendo el entendimiento de la polarización política.\n",
    "\n",
    "---\n",
    "\n",
    "📌 **Con esto se cumple el Ejercicio 2:** se conectó la API, se almacenaron posts y comentarios vinculados, y se realizó un EDA preliminar que añade valor.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yelp_scraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
